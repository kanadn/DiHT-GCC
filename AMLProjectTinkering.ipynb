{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanadn/DiHT-GCC/blob/main/AMLProjectTinkering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuTt5HCPgZGF"
      },
      "source": [
        "Mount Google drive, `cd` to the path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FesucFOTXIS_",
        "outputId": "8bc88c8d-6459-4fab-cacf-25cc2ba48b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/AdvancedML/AMLProject/diht\n"
          ]
        }
      ],
      "source": [
        "#mount Google drive and connect to a path\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/AdvancedML/AMLProject/diht"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u_sSSALggyQ"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frukEMiHDQfx"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwT4wNANglFC"
      },
      "source": [
        "For some reason we need a specific version of Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPfm0_UiaQ7T",
        "outputId": "80c582ec-71f0-459d-adcb-7401a24463d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diht 1.0 requires pillow==9.4.0, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow==9.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqIAXRsrg9yM"
      },
      "source": [
        "These models are available in the code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6KfmQwQIMjp",
        "outputId": "8a544eb9-7ca1-4d2e-b7a9-0a0f4aaaae2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['diht_vitb32_224px', 'diht_vitl14_336px', 'diht_vitb16_224px']\n"
          ]
        }
      ],
      "source": [
        "import diht\n",
        "print(diht.available_models())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PG6ej1IzPgl",
        "outputId": "8073e45f-9334-4d4b-ec59-52bf830044c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.59G/1.59G [01:51<00:00, 15.3MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text captions: ['a mountain', 'a beach', 'a desert']\n",
            "text caption probs: [[0.99370664 0.00514016 0.00115325]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import diht\n",
        "\n",
        "from diht import model_zoo\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "text_tokenizer, image_transform, model = model_zoo.load_model(\n",
        "    \"diht_vitl14_336px\", is_train=False\n",
        ")\n",
        "\n",
        "image = Image.open(\"infer_image.png\").convert(\"RGB\")\n",
        "image = image_transform(image).unsqueeze(0)\n",
        "text_captions = [\"a mountain\", \"a beach\", \"a desert\"]\n",
        "text = text_tokenizer(text_captions)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features, text_features, logit_scale = model(image, text)\n",
        "    logits_per_image = logit_scale * image_features @ text_features.T\n",
        "    probs = logits_per_image.softmax(dim=-1).numpy()\n",
        "\n",
        "print(f\"text captions: {text_captions}\")\n",
        "print(f\"text caption probs: {probs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX_YHnAJhCjl"
      },
      "source": [
        "Sample code is working, now let's do some tinkering..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOO3TOPqfgPk",
        "outputId": "0fe0fd04-40d2-4698-8ceb-a3e7e95bf2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text captions: ['a mountain', 'a lake', 'a mountain and a lake']\n",
            "text caption probs: [[0.01392776 0.01522721 0.97084504]]\n"
          ]
        }
      ],
      "source": [
        "text_captions2 = [\"a mountain\", \"a lake\", \"a mountain and a lake\"]\n",
        "texts = text_tokenizer(text_captions2)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features, text_features, logit_scale = model(image, texts)\n",
        "    logits_per_image = logit_scale * image_features @ text_features.T\n",
        "    probs = logits_per_image.softmax(dim=-1).numpy()\n",
        "\n",
        "print(f\"text captions: {text_captions2}\")\n",
        "print(f\"text caption probs: {probs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qokCdeschc10"
      },
      "source": [
        "The model seems to be smart :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIi_19kCwtw4"
      },
      "source": [
        "Now let's import Google's [Conceptual Captions](https://ai.google.com/research/ConceptualCaptions/) dataset...  \n",
        "Edit: Since the dataset only has image URLs, we need to fecth the images. This might take a lot of time, like, a lot!  \n",
        "The following approach stores the dataset into a map, I think. It failed once and I need to restart everything again. Seems very inefficient. Skip this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwmI6HkzzkpP"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Brv5hhXqxKsP"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import io\n",
        "import urllib\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "from datasets import load_dataset\n",
        "from datasets.utils.file_utils import get_datasets_user_agent\n",
        "\n",
        "\n",
        "USER_AGENT = get_datasets_user_agent()\n",
        "\n",
        "\n",
        "def fetch_single_image(image_url, timeout=None, retries=0):\n",
        "    for _ in range(retries + 1):\n",
        "        try:\n",
        "            request = urllib.request.Request(\n",
        "                image_url,\n",
        "                data=None,\n",
        "                headers={\"user-agent\": USER_AGENT},\n",
        "            )\n",
        "            with urllib.request.urlopen(request, timeout=timeout) as req:\n",
        "                image = PIL.Image.open(io.BytesIO(req.read()))\n",
        "            break\n",
        "        except Exception:\n",
        "            image = None\n",
        "    return image\n",
        "\n",
        "\n",
        "def fetch_images(batch, num_threads, timeout=None, retries=0):\n",
        "    fetch_single_image_with_args = partial(fetch_single_image, timeout=timeout, retries=retries)\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        batch[\"image\"] = list(executor.map(fetch_single_image_with_args, batch[\"image_url\"]))\n",
        "    return batch\n",
        "\n",
        "\n",
        "num_threads = 20\n",
        "dset = load_dataset(\"conceptual_captions\")\n",
        "dset = dset.map(fetch_images, batched=True, batch_size=100, fn_kwargs={\"num_threads\": num_threads})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKKmLt1TGd85"
      },
      "source": [
        "Found another way: https://github.com/igorbrigadir/DownloadConceptualCaptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7F8NZJJGs14",
        "outputId": "a01b0c34-a910-4fbf-e80d-0421067dd05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AdvancedML/AMLProject\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY0CiVFbHm19",
        "outputId": "b589009b-6958-4df7-fd82-769116745493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AdvancedML/AMLProject/DownloadConceptualCaptions\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/igorbrigadir/DownloadConceptualCaptions.git\n",
        "%cd DownloadConceptualCaptions/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9zPxam8IQFI"
      },
      "outputs": [],
      "source": [
        "!pip install python-magic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following step is problematic. Since the folder already has many images, the drive mount function is failing with error \"timed out\" :("
      ],
      "metadata": {
        "id": "i43v1dz_jwCr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiR3BvUOHzLB"
      },
      "outputs": [],
      "source": [
        "!python download_data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So I managed to download the data on my machine. Now the problem is, how to test this data?... I was planning to use Colab but looking at the sheer size of the data, Drive can't be used to store.  \n",
        "So now our task is to find an optimal way to test this gigantic dataset. Either on cloud or on our machines."
      ],
      "metadata": {
        "id": "le4oN6614R45"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "135nAEyyZzusKRiocan3UTbGzcIUFdZlr",
      "authorship_tag": "ABX9TyMBPPKKgVv8Jb+oHwMu4cZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}